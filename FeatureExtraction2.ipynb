{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " FeatureExtraction.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reubence/NLP-COURSEWORK/blob/master/FeatureExtraction2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSsodLXeVv_a",
        "colab_type": "text"
      },
      "source": [
        "**NLP Lecture 6 (24-12-19):** Remove '#' and @ , stopwords, numerics. Keep words containing alphabets. Use CountVectorizer, XgBoost/RandomForest/LightGBM and develop a Pipeline to Train and test on twitter data and make predictions\n",
        "\n",
        "Also find AUC/ROC, Recall & Precision with threshold values == 0.6, 0.7, 0.8\n",
        "\n",
        "Finally Predict on amazon reviews data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyfawyqfQr4C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfTransformer,CountVectorizer,TfidfVectorizer\n",
        "from nltk import word_tokenize\n",
        "import string \n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split as tts,GridSearchCV\n",
        "import lightgbm as lgb\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo2qujM8S-yq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "61ff0453-3365-4b16-c521-8eedeafe3e86"
      },
      "source": [
        "%reset"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Once deleted, variables cannot be recovered. Proceed (y/[n])? \n",
            "Nothing done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8ArbwuVQtl6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "91831c1f-01eb-4681-d214-b2e551042e99"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "nltk.download('words')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyYlOl1pQvsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  def remove_punctuations_fn(data):\n",
        "  data = data\n",
        "  translator = str.maketrans('', '', '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~1234567890')\n",
        "  data = data.translate(translator)\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDs24nKAQ5E3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_stop_tokenize(Sentence):\n",
        "  word_tokens = word_tokenize(remove_punctuations_fn(Sentence.lower())) \n",
        "    \n",
        "  filtered_sentence = [] \n",
        "  \n",
        "  for w in word_tokens: \n",
        "      if w not in stop_words: \n",
        "          filtered_sentence.append(w) \n",
        "  return filtered_sentence\n",
        "\n",
        "def convert(lst):\n",
        "  lst = remove_stop_tokenize(lst)        \n",
        "  return ' '.join(lst)\n",
        "\n",
        "def remove_non_english(Sentence):\n",
        "\n",
        "  words = set(nltk.corpus.words.words())\n",
        "\n",
        "  sent = Sentence\n",
        "  Clean = \" \".join(w for w in nltk.wordpunct_tokenize(sent) \\\n",
        "            if w.lower() in words or not w.isalpha())\n",
        "  return Clean\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi2dluJgQxzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twitr=pd.read_csv(\"https://raw.githubusercontent.com/zfz/twitter_corpus/master/full-corpus.csv\")\n",
        "df = pd.read_json(\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Office_Products_5.json.gz\",lines=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNajkrGlQ3by",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twitr = twitr.head(1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7p-dQ1suQ8mL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "3192adf7-ce00-42a6-8a9d-04cdb31e4bab"
      },
      "source": [
        "Sentence = twitr['TweetText'][2]\n",
        "Sentence"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hilarious @youtube video - guy does a duet with @apple 's Siri. Pretty much sums up the love affair! http://t.co/8ExbnQjY\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlsXYnODQ-rq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "53c966d3-291a-4299-e89d-0bf7f0974d41"
      },
      "source": [
        "temp = remove_stop_tokenize(Sentence)\n",
        "temp"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hilarious',\n",
              " 'youtube',\n",
              " 'video',\n",
              " 'guy',\n",
              " 'duet',\n",
              " 'apple',\n",
              " 'siri',\n",
              " 'pretty',\n",
              " 'much',\n",
              " 'sums',\n",
              " 'love',\n",
              " 'affair',\n",
              " 'httptcoexbnqjy']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMhaTxFcRGjA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twitr['Clean_tweet'] = twitr['TweetText'].apply(convert)\n",
        "twitr['Clean_tweet'] = twitr['Clean_tweet'].apply(remove_punctuations_fn)\n",
        "twitr['Clean_tweet'] = twitr['Clean_tweet'].apply(remove_non_english)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxeMbohBRIqx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "0e533f13-d6a7-41df-b23c-76b8d4509511"
      },
      "source": [
        "twitr['Clean_tweet']"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                        apple get crack\n",
              "1                                  apple carrier support\n",
              "2      hilarious video guy duet apple pretty much lov...\n",
              "3                      rim made easy switch apple see ya\n",
              "4                        reason got twitter thanks apple\n",
              "                             ...                        \n",
              "995                      apple upgrade helpful maddening\n",
              "996    hold apple last really like music selection mu...\n",
              "997                 win apple touch get hello world baby\n",
              "998                             poor substitute yo apple\n",
              "999                                       apple scrapple\n",
              "Name: Clean_tweet, Length: 1000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fywOgozjRVCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "steps = [('text',CountVectorizer()),('ensemble',RandomForestClassifier())]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBYAqLgyRXSH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipe = Pipeline(steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjFgg8imRa4c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "d4e8fe9e-e4fb-46f7-b742-d1b94f4e9c5c"
      },
      "source": [
        "twitr.columns"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Topic', 'Sentiment', 'TweetId', 'TweetDate', 'TweetText',\n",
              "       'Clean_tweet'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAJVpMDPRcLD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9d405748-a404-451f-e188-bb40434fccac"
      },
      "source": [
        "from sklearn.model_selection import train_test_split as tts\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(twitr['Clean_tweet'])\n",
        "print(vectorizer.get_feature_names())\n",
        "x_train,x_test,y_train,y_test = tts(X,twitr['Sentiment'],test_size=0.3, random_state=30)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ability', 'able', 'absolutely', 'accent', 'access', 'accidently', 'account', 'acquisition', 'across', 'active', 'activity', 'actually', 'add', 'added', 'addicted', 'address', 'admit', 'adobe', 'advance', 'advanced', 'advertise', 'advertising', 'advisor', 'affair', 'afford', 'agree', 'ah', 'ai', 'ailing', 'air', 'airdrop', 'airport', 'aka', 'ala', 'alamo', 'alarm', 'album', 'alcohol', 'alert', 'alive', 'allow', 'ally', 'almost', 'alone', 'already', 'also', 'although', 'alto', 'always', 'amazed', 'amazing', 'amongst', 'amount', 'amused', 'analysis', 'and', 'android', 'angry', 'annoying', 'another', 'answer', 'antitrust', 'anyone', 'anything', 'anyway', 'apologize', 'apology', 'apparently', 'appear', 'apple', 'apply', 'appointment', 'appropriately', 'apt', 'architecture', 'arent', 'argument', 'around', 'arrival', 'arrogant', 'art', 'article', 'artist', 'aside', 'ask', 'ass', 'assistant', 'ate', 'attention', 'audio', 'authorization', 'authorize', 'auto', 'available', 'ave', 'average', 'away', 'awesome', 'awful', 'aye', 'baby', 'back', 'backside', 'backup', 'bad', 'bag', 'bah', 'baked', 'ball', 'ban', 'bar', 'base', 'based', 'battery', 'batting', 'battle', 'beautiful', 'beef', 'bees', 'begging', 'begin', 'beginning', 'behind', 'believe', 'benefit', 'berry', 'best', 'bet', 'beta', 'better', 'beware', 'beyond', 'bidirectional', 'big', 'billion', 'bit', 'bitch', 'bite', 'biz', 'black', 'blackberry', 'blast', 'blaze', 'blend', 'bless', 'blessed', 'bloody', 'blow', 'blue', 'bode', 'body', 'boo', 'book', 'booked', 'booted', 'bottom', 'bought', 'bound', 'bouquet', 'boy', 'brain', 'brand', 'bravo', 'break', 'breaking', 'brick', 'brightness', 'brilliance', 'brilliant', 'bring', 'broke', 'broken', 'brother', 'brought', 'bud', 'buddy', 'bug', 'bummer', 'bump', 'bunch', 'buried', 'burn', 'bus', 'business', 'busy', 'butler', 'buttery', 'button', 'buttons', 'buy', 'buzz', 'cable', 'calendar', 'call', 'calling', 'came', 'camera', 'camper', 'canada', 'cancer', 'canon', 'cant', 'cap', 'car', 'card', 'care', 'careful', 'carrier', 'case', 'cat', 'catastrophically', 'cause', 'center', 'ceremoniously', 'certain', 'champ', 'chance', 'change', 'chaos', 'charge', 'charger', 'charging', 'chat', 'cheap', 'check', 'checked', 'cheer', 'child', 'chips', 'choice', 'choose', 'chrome', 'class', 'click', 'client', 'clock', 'close', 'closed', 'closet', 'cloud', 'cloudy', 'club', 'clue', 'coach', 'cofounder', 'coincidence', 'color', 'come', 'coming', 'community', 'compact', 'company', 'comparison', 'compatible', 'competitive', 'compilation', 'complain', 'complete', 'completely', 'component', 'computer', 'con', 'concrete', 'configure', 'confused', 'connect', 'connection', 'connector', 'consider', 'considered', 'considering', 'consolidation', 'constrained', 'contact', 'content', 'continued', 'continuously', 'contract', 'control', 'convert', 'converting', 'cool', 'cope', 'copy', 'cord', 'corporate', 'correct', 'correction', 'cos', 'cost', 'could', 'couple', 'court', 'covent', 'covered', 'crack', 'cracked', 'cranial', 'crap', 'crash', 'crazy', 'cream', 'create', 'creative', 'credit', 'crome', 'crossed', 'crowd', 'crushed', 'cue', 'curious', 'current', 'currently', 'curse', 'customer', 'cut', 'cute', 'cutting', 'da', 'dad', 'daily', 'damage', 'damn', 'dark', 'data', 'daughter', 'day', 'days', 'de', 'dead', 'deaf', 'deal', 'dealing', 'dear', 'death', 'debut', 'decide', 'declined', 'default', 'define', 'definitely', 'delete', 'deliver', 'denounce', 'dependent', 'design', 'designed', 'developer', 'device', 'dick', 'didnt', 'die', 'difference', 'digital', 'dilation', 'direct', 'dis', 'disabled', 'disagree', 'disappear', 'disappointed', 'disappointing', 'disappointment', 'disaster', 'discount', 'discovery', 'dissent', 'dock', 'document', 'documentary', 'dodgy', 'doesnt', 'dogs', 'domain', 'domination', 'donate', 'donated', 'done', 'dont', 'door', 'dope', 'dose', 'doubt', 'downgrade', 'downtown', 'drain', 'drew', 'driving', 'dropping', 'drying', 'dude', 'due', 'duet', 'duff', 'dumb', 'duplication', 'durable', 'dying', 'ear', 'early', 'earnings', 'earth', 'easier', 'easiest', 'easter', 'easy', 'eating', 'edge', 'editor', 'education', 'effort', 'eh', 'either', 'el', 'electric', 'elegance', 'else', 'em', 'employee', 'empty', 'end', 'ending', 'endless', 'enhance', 'enough', 'entering', 'entire', 'entrepreneur', 'equal', 'equipment', 'equivalent', 'eric', 'error', 'escort', 'especially', 'eta', 'eu', 'even', 'evening', 'event', 'ever', 'every', 'everybody', 'everyone', 'everything', 'everywhere', 'evidence', 'evil', 'evolution', 'except', 'exchange', 'excited', 'exclusive', 'exercise', 'exhibit', 'expanded', 'expensive', 'experience', 'explain', 'explaining', 'extend', 'eye', 'eyelash', 'face', 'fact', 'factory', 'fade', 'fail', 'failing', 'fair', 'family', 'fan', 'fantasy', 'far', 'fast', 'faster', 'fault', 'faulty', 'favorite', 'feature', 'featured', 'feeding', 'feel', 'feeling', 'female', 'figure', 'figured', 'file', 'final', 'finally', 'finance', 'financial', 'find', 'fine', 'finger', 'finish', 'first', 'fix', 'fixed', 'fixing', 'flash', 'flat', 'flawless', 'flight', 'focus', 'folder', 'follow', 'following', 'font', 'foolish', 'football', 'force', 'ford', 'forever', 'forget', 'form', 'former', 'forward', 'found', 'founder', 'four', 'free', 'freeze', 'friend', 'front', 'frozen', 'fruit', 'frustration', 'full', 'fully', 'fun', 'function', 'functionality', 'funny', 'future', 'fuzzball', 'gain', 'galaxy', 'game', 'garbage', 'garden', 'gave', 'gay', 'gear', 'gee', 'geek', 'gen', 'generation', 'genius', 'get', 'getting', 'giant', 'gift', 'give', 'giving', 'glad', 'glass', 'global', 'globally', 'go', 'god', 'goes', 'going', 'gon', 'gone', 'good', 'goodwill', 'got', 'governor', 'grandma', 'graphic', 'grass', 'gratis', 'great', 'greatly', 'greedy', 'greener', 'group', 'growth', 'guarantee', 'guess', 'gun', 'guy', 'ha', 'hairline', 'half', 'hall', 'hand', 'handle', 'handled', 'handy', 'hanging', 'happen', 'happening', 'happy', 'hard', 'harder', 'hardware', 'hate', 'hater', 'havent', 'head', 'headline', 'hear', 'hell', 'hello', 'help', 'helpful', 'hero', 'hey', 'hi', 'hide', 'high', 'hilarious', 'hip', 'hire', 'history', 'hit', 'ho', 'hockey', 'hold', 'holder', 'holding', 'home', 'honest', 'hong', 'honor', 'hook', 'hope', 'hopeful', 'hopefully', 'horizontal', 'horse', 'hospital', 'hotel', 'hour', 'household', 'however', 'hubby', 'huge', 'huh', 'humor', 'hungry', 'hurry', 'hut', 'hypo', 'ice', 'icon', 'id', 'identity', 'ie', 'ill', 'image', 'imagine', 'immediate', 'imminent', 'immobile', 'implant', 'implementation', 'importance', 'importantly', 'impossible', 'impressive', 'improve', 'improvement', 'inanimate', 'incapable', 'incase', 'include', 'included', 'incompatible', 'inconvenient', 'increasing', 'incredible', 'indicator', 'inept', 'infamous', 'inferno', 'inform', 'infringement', 'injunction', 'innovation', 'insanely', 'insert', 'insertion', 'insist', 'inspire', 'install', 'instead', 'insurance', 'integrate', 'intellectual', 'intended', 'interconnect', 'interesting', 'internode', 'interrupting', 'intriguing', 'invent', 'invention', 'inventor', 'inventory', 'investigate', 'invisible', 'io', 'iso', 'issue', 'it', 'item', 'jane', 'japan', 'jean', 'jihad', 'job', 'jolly', 'karaoke', 'keep', 'key', 'keyboard', 'keynote', 'kill', 'killing', 'kind', 'knew', 'know', 'knowing', 'known', 'kudos', 'la', 'lack', 'laid', 'lame', 'landscape', 'last', 'late', 'latter', 'launch', 'lawsuit', 'lead', 'leadership', 'leading', 'league', 'learn', 'learned', 'learning', 'least', 'leaving', 'left', 'legacy', 'legal', 'leopard', 'less', 'lesson', 'let', 'life', 'light', 'like', 'likely', 'liking', 'limited', 'line', 'lined', 'link', 'lion', 'list', 'listed', 'listening', 'little', 'live', 'living', 'lo', 'local', 'location', 'lock', 'locked', 'log', 'logged', 'logging', 'login', 'lonely', 'long', 'longer', 'look', 'looking', 'loop', 'loose', 'lose', 'losing', 'loss', 'lost', 'lot', 'love', 'loving', 'lower', 'loyalty', 'luck', 'lunch', 'mac', 'machine', 'mack', 'mad', 'maddening', 'made', 'madness', 'magazine', 'magic', 'magical', 'magically', 'mail', 'main', 'mainly', 'major', 'make', 'making', 'mall', 'man', 'manage', 'management', 'mandarin', 'mansion', 'many', 'map', 'march', 'mark', 'market', 'marketing', 'mary', 'match', 'matter', 'may', 'maybe', 'mean', 'meant', 'media', 'meet', 'meeting', 'memorial', 'memory', 'mention', 'mentor', 'merge', 'message', 'methinks', 'mi', 'middle', 'might', 'mightily', 'mighty', 'migrate', 'million', 'millions', 'min', 'mind', 'mine', 'mines', 'minute', 'misread', 'miss', 'missing', 'mission', 'mo', 'mobile', 'mode', 'model', 'modify', 'moment', 'monopolistic', 'month', 'morning', 'mortar', 'mourning', 'mouse', 'move', 'moving', 'much', 'multiple', 'music', 'must', 'na', 'nam', 'name', 'native', 'nauseous', 'navigate', 'nearest', 'need', 'needless', 'needs', 'negro', 'net', 'network', 'never', 'new', 'newsstand', 'newton', 'next', 'nexus', 'nice', 'night', 'nobody', 'none', 'nonstop', 'nope', 'nostalgia', 'note', 'nothing', 'notification', 'notify', 'nuance', 'nugget', 'number', 'obnoxious', 'obscure', 'obviously', 'occur', 'odd', 'offering', 'office', 'official', 'officially', 'offing', 'often', 'oh', 'old', 'older', 'omission', 'one', 'onto', 'open', 'opening', 'operating', 'opinion', 'opportunity', 'opposite', 'option', 'order', 'ordered', 'organic', 'original', 'os', 'ouch', 'outlook', 'outside', 'overall', 'overbearing', 'overboard', 'overcapacity', 'overhaul', 'owl', 'owner', 'ownership', 'page', 'pain', 'painful', 'painfully', 'painless', 'painted', 'pancreatic', 'para', 'part', 'partner', 'partnership', 'pass', 'passing', 'password', 'past', 'patent', 'patiently', 'pay', 'paying', 'people', 'per', 'perfect', 'perfectly', 'perhaps', 'period', 'perpetual', 'person', 'personal', 'petty', 'phone', 'photo', 'pic', 'pick', 'piece', 'pile', 'pink', 'piracy', 'pith', 'place', 'placement', 'plan', 'planking', 'plate', 'platform', 'play', 'please', 'plus', 'point', 'pointing', 'policy', 'poll', 'pondering', 'poop', 'poor', 'poorly', 'pop', 'popular', 'portion', 'possible', 'possibly', 'post', 'power', 'powered', 'premise', 'preorder', 'present', 'pretty', 'previous', 'price', 'principal', 'printed', 'printer', 'pro', 'problem', 'proceeds', 'process', 'product', 'productivity', 'professional', 'profiting', 'program', 'project', 'promise', 'promising', 'proof', 'proper', 'properly', 'property', 'props', 'protect', 'protection', 'provide', 'proving', 'public', 'publicly', 'puck', 'pull', 'pump', 'pun', 'purchase', 'purely', 'purpose', 'push', 'put', 'python', 'quality', 'quarter', 'question', 'quickly', 'quite', 'racism', 'ram', 'ranch', 'randomly', 'rape', 'rapidly', 'rather', 'ray', 'reaching', 'reaction', 'read', 'reader', 'realize', 'really', 'reason', 'rebuild', 'receipt', 'received', 'recession', 'recognition', 'record', 'recover', 'red', 'regent', 'region', 'registered', 'reinstall', 'relate', 'release', 'relevant', 'reliable', 'remember', 'remind', 'reminder', 'remote', 'removable', 'remove', 'removing', 'rename', 'render', 'renewal', 'rep', 'repair', 'replace', 'replacement', 'reply', 'represent', 'reps', 'request', 'research', 'reservation', 'reserve', 'resilience', 'resolve', 'respect', 'respond', 'response', 'rest', 'restore', 'retail', 'retrieve', 'return', 'reunion', 'revenue', 'review', 'rice', 'right', 'rim', 'ring', 'ringing', 'rip', 'roaring', 'robot', 'roll', 'rolling', 'room', 'rot', 'row', 'rug', 'run', 'running', 'sa', 'sad', 'safari', 'said', 'sale', 'salesperson', 'salute', 'sandwich', 'sarcasm', 'save', 'saved', 'saving', 'saw', 'say', 'saying', 'schedule', 'school', 'scrapple', 'screen', 'screw', 'screwed', 'screwing', 'scroll', 'se', 'search', 'searching', 'sec', 'second', 'secret', 'section', 'security', 'see', 'seeing', 'seemingly', 'seen', 'selection', 'self', 'sell', 'selling', 'send', 'sending', 'sense', 'sent', 'sequence', 'seriously', 'server', 'service', 'session', 'set', 'setting', 'settle', 'setup', 'seven', 'shagged', 'share', 'shift', 'ship', 'shoot', 'short', 'show', 'shower', 'showing', 'shrewd', 'shuffle', 'shut', 'sick', 'side', 'sigh', 'sign', 'signal', 'silicon', 'silly', 'silver', 'similar', 'simple', 'simply', 'since', 'sincerely', 'single', 'sinking', 'siris', 'sis', 'sister', 'site', 'sith', 'situation', 'six', 'skin', 'sleep', 'slide', 'slider', 'slinging', 'slipping', 'sloppy', 'slow', 'slowly', 'slows', 'small', 'smart', 'smell', 'snatched', 'snippy', 'snow', 'social', 'soho', 'sold', 'solution', 'solve', 'somehow', 'someone', 'something', 'sometimes', 'song', 'soon', 'sorry', 'sought', 'sound', 'space', 'speak', 'specs', 'speech', 'speed', 'spell', 'spend', 'spending', 'spent', 'spinning', 'spoiled', 'spoke', 'spontaneous', 'spontaneously', 'sports', 'spotted', 'spray', 'sprint', 'sprung', 'squad', 'st', 'stable', 'staff', 'staffed', 'staged', 'stand', 'standing', 'star', 'start', 'state', 'station', 'stay', 'stayed', 'step', 'sticking', 'sticky', 'still', 'stink', 'stock', 'stocks', 'stolen', 'stood', 'stop', 'storage', 'store', 'story', 'straight', 'strange', 'strategy', 'street', 'struggling', 'stuck', 'student', 'stuff', 'stupid', 'style', 'stylus', 'subscribe', 'substitute', 'succeed', 'success', 'suck', 'sucking', 'sudden', 'suddenly', 'suffering', 'suing', 'suit', 'summer', 'support', 'sure', 'surely', 'survey', 'surviving', 'swallow', 'sweet', 'switch', 'switcher', 'symbol', 'sync', 'system', 'ta', 'tab', 'tablet', 'take', 'taken', 'taking', 'talk', 'talking', 'tax', 'team', 'tear', 'tech', 'technology', 'techy', 'telegraph', 'tell', 'terminal', 'terrible', 'test', 'testing', 'text', 'th', 'thank', 'thankful', 'thankfully', 'thanks', 'thats', 'thee', 'theft', 'theres', 'theyre', 'thing', 'think', 'thinking', 'tho', 'thorn', 'thorough', 'though', 'thought', 'throat', 'throne', 'throw', 'thunderbird', 'thunderbolt', 'thus', 'tie', 'tiger', 'tighten', 'til', 'till', 'time', 'timed', 'times', 'timing', 'tint', 'tired', 'titanic', 'title', 'today', 'together', 'toggle', 'told', 'tomorrow', 'tone', 'tonight', 'tonite', 'took', 'top', 'tossing', 'total', 'totally', 'touch', 'towards', 'traffic', 'tragic', 'training', 'translator', 'trash', 'tribute', 'trick', 'tried', 'trip', 'triple', 'trouble', 'troublemaker', 'true', 'truly', 'try', 'trying', 'tube', 'turn', 'turned', 'turning', 'turns', 'tweet', 'twit', 'twitter', 'two', 'type', 'ugh', 'um', 'umber', 'unauthorized', 'unbelievable', 'unconventional', 'undo', 'unexpected', 'unhappy', 'unique', 'unladen', 'unless', 'unlocked', 'unlocking', 'unquality', 'unreal', 'unveiled', 'unwanted', 'upcoming', 'update', 'upgrade', 'upset', 'upstairs', 'ur', 'us', 'usable', 'usage', 'use', 'used', 'useful', 'useless', 'user', 'utility', 'utter', 'utterly', 'valley', 'valuable', 'verge', 'version', 'vertical', 'via', 'vibrate', 'vibrating', 'video', 'vie', 'virtual', 'visit', 'visual', 'voice', 'volume', 'wack', 'wait', 'waiting', 'walk', 'wall', 'walled', 'wan', 'want', 'war', 'warm', 'warning', 'warranty', 'wash', 'wasnt', 'wasted', 'wasting', 'watch', 'watched', 'watching', 'way', 'weather', 'web', 'week', 'weekend', 'weekly', 'weird', 'welcome', 'well', 'wen', 'went', 'werent', 'west', 'whats', 'wheel', 'white', 'whoa', 'whoever', 'whole', 'whoops', 'wid', 'wife', 'win', 'winning', 'wireless', 'wise', 'wish', 'wished', 'wit', 'witchcraft', 'within', 'without', 'woke', 'wonder', 'wonky', 'wont', 'word', 'work', 'worked', 'working', 'works', 'workshop', 'world', 'worse', 'worst', 'worth', 'would', 'wouldnt', 'wow', 'write', 'wrong', 'ya', 'yahoo', 'yapping', 'yea', 'yeah', 'year', 'yellow', 'yelp', 'yes', 'yesterday', 'yet', 'yo', 'young', 'youve', 'yr', 'zero']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbWvEdNNRdhL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = pd.DataFrame(x_train.toarray(),columns=vectorizer.get_feature_names())\n",
        "x_test = pd.DataFrame(x_test.toarray(),columns=vectorizer.get_feature_names())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1V4cdDHJRg6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf = RandomForestClassifier()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59oIO5QjRicB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = {'max_depth': [10, 20, 30, None],\n",
        " 'max_features': ['sqrt'],\n",
        " 'min_samples_leaf': [1, 2, 4],\n",
        " 'min_samples_split': [2, 5, 10],\n",
        " 'n_estimators': range(10,50,10)}\n",
        "gs_rf = GridSearchCV(estimator = rf, param_grid = params, \n",
        "                          cv = 5, n_jobs = 10, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uq4p_0gRRj3B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "94705b8b-0082-484b-f028-3f435ae8379b"
      },
      "source": [
        "gs_rf.fit(x_train,y_train)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
            "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    8.6s\n",
            "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:   18.6s\n",
            "[Parallel(n_jobs=10)]: Done 430 tasks      | elapsed:   35.8s\n",
            "[Parallel(n_jobs=10)]: Done 720 out of 720 | elapsed:   58.9s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
              "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators='warn', n_jobs=None,\n",
              "                                              oob_score=False,\n",
              "                                              random_state=None, verbose=0,\n",
              "                                              warm_start=False),\n",
              "             iid='warn', n_jobs=10,\n",
              "             param_grid={'max_depth': [10, 20, 30, None],\n",
              "                         'max_features': ['sqrt'],\n",
              "                         'min_samples_leaf': [1, 2, 4],\n",
              "                         'min_samples_split': [2, 5, 10],\n",
              "                         'n_estimators': range(10, 50, 10)},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEMIVhkLRlia",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "0de94df9-ecfa-4aec-bbb7-e44ca6486b57"
      },
      "source": [
        "print(classification_report(gs_rf.predict(x_test),y_test))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.51      0.56      0.53        79\n",
            "     neutral       0.84      0.69      0.76       200\n",
            "    positive       0.33      0.76      0.46        21\n",
            "\n",
            "    accuracy                           0.66       300\n",
            "   macro avg       0.56      0.67      0.58       300\n",
            "weighted avg       0.71      0.66      0.68       300\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4H5DGHHmRoJ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = {\n",
        "    \"objective\" : \"multiclass\",\n",
        "    'boosting_type': 'gbdt',\n",
        "    'objective': 'multiclass',\n",
        "    'num_class':3,\n",
        "    'learning_rate':0.01,\n",
        "    'max_depth': 7,\n",
        "    'num_leaves': 127,\n",
        "    'feature_fraction': 0.4,\n",
        "    'bagging_freq': 10,\n",
        "    'num_iterations':1000 ,\n",
        "    'max_bin' : 32}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btSchBnBSLTt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le = LabelEncoder()  \n",
        "d_train = lgb.Dataset(x_train,le.fit_transform(y_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m-JPX-6SLvO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "1ddc2988-c2c5-442e-96f1-2b3fa2810a27"
      },
      "source": [
        "clf = lgb.train(params,d_train,100)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxuH0kPYSM1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = clf.predict(x_test)\n",
        "best_preds= [np.argmax(line) for line in preds]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BREikc4TG4h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.bincount((le.fit_transform(y_train)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtZ-Oe28Tt4d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "e4c96298-03a4-4f48-f8f9-c5f78ddffb39"
      },
      "source": [
        "print(classification_report(le.inverse_transform(best_preds),y_test))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.14      0.39      0.20        31\n",
            "     neutral       0.90      0.57      0.70       258\n",
            "    positive       0.15      0.64      0.24        11\n",
            "\n",
            "    accuracy                           0.56       300\n",
            "   macro avg       0.39      0.53      0.38       300\n",
            "weighted avg       0.79      0.56      0.63       300\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0iCR0U8TvWC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dfd28e08-c0e0-4bcd-a4f5-30ce1d83a940"
      },
      "source": [
        "np.bincount((best_preds))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 31, 258,  11])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2l4PpvbTwq5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "995f589b-2930-40c4-9bef-fb09b48221c9"
      },
      "source": [
        "preds = clf.predict(x_train)\n",
        "best_preds_train= [np.argmax(line) for line in preds]\n",
        "print(classification_report(le.inverse_transform(best_preds_train),y_train))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.29      0.65      0.40       101\n",
            "     neutral       0.93      0.57      0.70       582\n",
            "    positive       0.09      0.65      0.17        17\n",
            "\n",
            "    accuracy                           0.58       700\n",
            "   macro avg       0.44      0.62      0.42       700\n",
            "weighted avg       0.81      0.58      0.65       700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCleb4MhTybQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "outputId": "363a1982-a712-478b-cef9-23c36ad7f718"
      },
      "source": [
        "# 0.6 Threshold lgbm\n",
        "preds = clf.predict(x_train)\n",
        "best_preds_train= [np.argmax(line) for line in preds]\n",
        "print(\"Default Threshold for lgbm : \\n\",classification_report(le.inverse_transform(best_preds_train),y_train))\n",
        "def thresh_1(array):\n",
        "  a = []\n",
        "  for i in range(len(array)):\n",
        "    if max(array[i])>0.6:\n",
        "      a.append(np.argmax(array[i]))\n",
        "    else:\n",
        "      a.append(2)\n",
        "  return a\n",
        "print(\"\\n 0.6 Threshold for lgbm : \\n\",classification_report(le.inverse_transform(thresh_1(preds)),y_train))\n",
        "      \n",
        "### Random forest\n",
        "pred_rf = gs_rf.predict_proba(x_test)\n",
        "print(\"Default Threshold for rf : \\n\",(classification_report(gs_rf.predict(x_test),y_test)))\n",
        "print(\"\\n 0.6 threshold for rf : \\n\",classification_report(le.inverse_transform(thresh_1(pred_rf)),y_test) )"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Default Threshold for lgbm : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.29      0.65      0.40       101\n",
            "     neutral       0.93      0.57      0.70       582\n",
            "    positive       0.09      0.65      0.17        17\n",
            "\n",
            "    accuracy                           0.58       700\n",
            "   macro avg       0.44      0.62      0.42       700\n",
            "weighted avg       0.81      0.58      0.65       700\n",
            "\n",
            "\n",
            " 0.6 Threshold for lgbm : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.15      0.77      0.25        44\n",
            "     neutral       0.37      0.73      0.50       181\n",
            "    positive       0.81      0.20      0.32       475\n",
            "\n",
            "    accuracy                           0.37       700\n",
            "   macro avg       0.44      0.57      0.35       700\n",
            "weighted avg       0.66      0.37      0.36       700\n",
            "\n",
            "Default Threshold for rf : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.51      0.56      0.53        79\n",
            "     neutral       0.84      0.69      0.76       200\n",
            "    positive       0.33      0.76      0.46        21\n",
            "\n",
            "    accuracy                           0.66       300\n",
            "   macro avg       0.56      0.67      0.58       300\n",
            "weighted avg       0.71      0.66      0.68       300\n",
            "\n",
            "\n",
            " 0.6 threshold for rf : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.26      0.72      0.39        32\n",
            "     neutral       0.51      0.72      0.60       116\n",
            "    positive       0.65      0.20      0.31       152\n",
            "\n",
            "    accuracy                           0.46       300\n",
            "   macro avg       0.47      0.55      0.43       300\n",
            "weighted avg       0.55      0.46      0.43       300\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-H6gh5hYahEl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "outputId": "48965988-d5d9-4cb6-ea2d-a97b8f562a8d"
      },
      "source": [
        "#0.7 Threshold\n",
        "preds = clf.predict(x_train)\n",
        "best_preds_train= [np.argmax(line) for line in preds]\n",
        "print(\"Default Threshold for lgbm : \\n\",classification_report(le.inverse_transform(best_preds_train),y_train))\n",
        "def thresh_2(array):\n",
        "  a = []\n",
        "  for i in range(len(array)):\n",
        "    if max(array[i])>0.7:\n",
        "      a.append(np.argmax(array[i]))\n",
        "    else:\n",
        "      a.append(2)\n",
        "  return a\n",
        "print(\"\\n 0.7 Threshold for lgbm : \\n\",classification_report(le.inverse_transform(thresh_2(preds)),y_train))\n",
        "###For rf\n",
        "pred_rf = gs_rf.predict_proba(x_test)\n",
        "print(\"Default Threshold for rf : \\n\",(classification_report(gs_rf.predict(x_test),y_test)))\n",
        "print(\"\\n 0.6 threshold for rf : \\n\",classification_report(le.inverse_transform(thresh_2(pred_rf)),y_test) )"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Default Threshold for lgbm : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.29      0.65      0.40       101\n",
            "     neutral       0.93      0.57      0.70       582\n",
            "    positive       0.09      0.65      0.17        17\n",
            "\n",
            "    accuracy                           0.58       700\n",
            "   macro avg       0.44      0.62      0.42       700\n",
            "weighted avg       0.81      0.58      0.65       700\n",
            "\n",
            "\n",
            " 0.7 Threshold for lgbm : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.09      0.80      0.16        25\n",
            "     neutral       0.08      0.72      0.14        39\n",
            "    positive       0.95      0.17      0.29       636\n",
            "\n",
            "    accuracy                           0.23       700\n",
            "   macro avg       0.37      0.56      0.20       700\n",
            "weighted avg       0.87      0.23      0.28       700\n",
            "\n",
            "Default Threshold for rf : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.51      0.56      0.53        79\n",
            "     neutral       0.84      0.69      0.76       200\n",
            "    positive       0.33      0.76      0.46        21\n",
            "\n",
            "    accuracy                           0.66       300\n",
            "   macro avg       0.56      0.67      0.58       300\n",
            "weighted avg       0.71      0.66      0.68       300\n",
            "\n",
            "\n",
            " 0.6 threshold for rf : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.15      0.87      0.25        15\n",
            "     neutral       0.41      0.81      0.55        84\n",
            "    positive       0.88      0.21      0.34       201\n",
            "\n",
            "    accuracy                           0.41       300\n",
            "   macro avg       0.48      0.63      0.38       300\n",
            "weighted avg       0.71      0.41      0.39       300\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DIi8x_dajUH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "outputId": "d5afdecf-67d1-4b97-de80-caf99e485b49"
      },
      "source": [
        "#0.8 Threshold\n",
        "preds = clf.predict(x_train)\n",
        "best_preds_train= [np.argmax(line) for line in preds]\n",
        "print(\"Default Threshold for lgbm : \\n\",classification_report(le.inverse_transform(best_preds_train),y_train))\n",
        "def thresh_3(array):\n",
        "  a = []\n",
        "  for i in range(len(array)):\n",
        "    if max(array[i])>0.8:\n",
        "      a.append(np.argmax(array[i]))\n",
        "    else:\n",
        "      a.append(2)\n",
        "  return a\n",
        "print(\"\\n 0.8 Threshold for lgbm : \\n\",classification_report(le.inverse_transform(thresh_3(preds)),y_train))\n",
        "      \n",
        "###For rf\n",
        "pred_rf = gs_rf.predict_proba(x_test)\n",
        "print(\"Default Threshold for rf : \\n\",(classification_report(gs_rf.predict(x_test),y_test)))\n",
        "print(\"\\n 0.6 threshold for rf : \\n\",classification_report(le.inverse_transform(thresh_3(pred_rf)),y_test) )\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Default Threshold for lgbm : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.29      0.65      0.40       101\n",
            "     neutral       0.93      0.57      0.70       582\n",
            "    positive       0.09      0.65      0.17        17\n",
            "\n",
            "    accuracy                           0.58       700\n",
            "   macro avg       0.44      0.62      0.42       700\n",
            "weighted avg       0.81      0.58      0.65       700\n",
            "\n",
            "\n",
            " 0.8 Threshold for lgbm : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.03      1.00      0.05         6\n",
            "     neutral       0.03      1.00      0.07        12\n",
            "    positive       1.00      0.17      0.29       682\n",
            "\n",
            "    accuracy                           0.19       700\n",
            "   macro avg       0.35      0.72      0.14       700\n",
            "weighted avg       0.98      0.19      0.28       700\n",
            "\n",
            "Default Threshold for rf : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.51      0.56      0.53        79\n",
            "     neutral       0.84      0.69      0.76       200\n",
            "    positive       0.33      0.76      0.46        21\n",
            "\n",
            "    accuracy                           0.66       300\n",
            "   macro avg       0.56      0.67      0.58       300\n",
            "weighted avg       0.71      0.66      0.68       300\n",
            "\n",
            "\n",
            " 0.6 threshold for rf : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.02      0.67      0.04         3\n",
            "     neutral       0.29      0.81      0.43        59\n",
            "    positive       0.90      0.18      0.30       238\n",
            "\n",
            "    accuracy                           0.31       300\n",
            "   macro avg       0.40      0.55      0.26       300\n",
            "weighted avg       0.77      0.31      0.32       300\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYr7y7Odak7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}